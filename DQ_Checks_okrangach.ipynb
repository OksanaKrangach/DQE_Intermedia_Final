{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e0fb6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Adjust display settings\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content of DataFrame cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1c209c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of links\n",
    "csv_path = '/home/datalab-user/Raw_Data_Validation.csv'\n",
    "\n",
    "csv_carriers = '/home/datalab-user/source_ok/carriers.csv'\n",
    "csv_airports = '/home/datalab-user/source_ok/airports.csv'\n",
    "csv_flights = '/home/datalab-user/source_ok/flights.csv'\n",
    "\n",
    "parquet_carriers = '/home/datalab-user/raw_ok/carriers'\n",
    "parquet_airports = '/home/datalab-user/raw_ok/airports'\n",
    "parquet_flights = '/home/datalab-user/raw_ok/flights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "82f31b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Functions for the DataFrame and .csv file Raw_Data_Validation to store check results\n",
    "\n",
    "def initialize_validation_dataframe():\n",
    "    \"\"\"\n",
    "    Initialize the Raw_Data_Validation DataFrame or load existing DataFrame from CSV if it exists.\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        # Load existing DataFrame from CSV\n",
    "        Raw_Data_Validation = pd.read_csv(csv_path, keep_default_na=False)\n",
    "    else:\n",
    "        # Create a new DataFrame if CSV doesn't exist\n",
    "        Raw_Data_Validation = pd.DataFrame(columns=['Num', 'Table', 'DQ check', 'Column', 'Status', 'Bad Data', 'Test Case'])\n",
    "    \n",
    "    return Raw_Data_Validation\n",
    "\n",
    "def save_validation_results(Raw_Data_Validation):\n",
    "    \"\"\"\n",
    "    Save the Raw_Data_Validation DataFrame to a CSV file.\n",
    "    \"\"\"\n",
    "    Raw_Data_Validation.to_csv(csv_path, index=False)\n",
    "\n",
    "def add_validation_result(Raw_Data_Validation, table, dq_check, column, status, bad_data, tc_num):\n",
    "    \"\"\"\n",
    "    Add a new validation result to the Raw_Data_Validation DataFrame.\n",
    "    \"\"\"\n",
    "    num = len(Raw_Data_Validation) + 1\n",
    "    new_row = {\n",
    "        'Num': num,\n",
    "        'Table': table,\n",
    "        'DQ check': dq_check,\n",
    "        'Column': column,\n",
    "        'Status': status,\n",
    "        'Bad Data': bad_data,\n",
    "        'Test Case': tc_num\n",
    "    }\n",
    "    Raw_Data_Validation = Raw_Data_Validation.append(new_row, ignore_index=True)\n",
    "\n",
    "    return Raw_Data_Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e2074f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_validation_dataframe():\n",
    "    \"\"\"\n",
    "    Drop Raw_Data_Validation DataFrame and delete existing CSV if it exists.\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        # Remove existing CSV\n",
    "        os.remove(csv_path)\n",
    "    \n",
    "    # Drop Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = pd.DataFrame(columns=['Num', 'Table', 'DQ check', 'Column', 'Status', 'Bad Data', 'Test Case'])\n",
    "    \n",
    "    return Raw_Data_Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fa5c908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values_csv(folder_path, table_name, dq_check, column_name, tc_num):\n",
    "    \"\"\"\n",
    "    Perform completeness check for NULL or empty values in a specific column of csv files.\n",
    "    \n",
    "    Arguments:\n",
    "    folder_path (str): Path to the folder containing Parquet files.\n",
    "    table_name (str): Name of the table (equal to the folder name).\n",
    "    column_name (str): Name of the column to perform completeness check on.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()\n",
    "    \n",
    "    # Load CSV file from the specified source folder into DataFrame\n",
    "    source_df = pd.read_csv(folder_path, keep_default_na=False)\n",
    "    \n",
    "    # Call check_null_values function to perform check and save results into the Raw_Data_Validation\n",
    "    check_null_values(source_df, table_name, dq_check, column_name, tc_num)\n",
    "    \n",
    "    return    \n",
    "\n",
    "def check_null_values_parquet(folder_path, table_name, dq_check, column_name, tc_num):\n",
    "    \"\"\"\n",
    "    Perform completeness check for NULL or empty values in a specific column of Parquet files.\n",
    "    \n",
    "    Arguments:\n",
    "    folder_path (str): Path to the folder containing Parquet files.\n",
    "    table_name (str): Name of the table (equal to the folder name).\n",
    "    column_name (str): Name of the column to perform completeness check on.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "       \n",
    "    # Load Parquet files from the specified target folder and concatenate them into one DataFrame\n",
    "    target_df = pd.concat([pq.read_table(os.path.join(folder_path, f)).to_pandas() \n",
    "                           for f in os.listdir(folder_path) if f.endswith('.parquet')],\n",
    "                          ignore_index=True)\n",
    "        \n",
    "    # Call check_null_values function to perform check and save results into the Raw_Data_Validation\n",
    "    check_null_values(target_df, table_name, dq_check, column_name, tc_num)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def check_null_values(table_df, table_name, dq_check, column_name, tc_num):\n",
    "    \n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()\n",
    "    \n",
    "    # Check for NULL or empty values in the specified column of combined_df\n",
    "    bad_data_indices = table_df[table_df[column_name].isnull() | (table_df[column_name] == '')].index\n",
    "    \n",
    "    # Get next indices (index + 1) for incorrect rows to start from 1\n",
    "    next_indices = [idx + 1 for idx in bad_data_indices]     \n",
    "    \n",
    "    # Determine the status based on completeness check\n",
    "    if len(next_indices) == 0:\n",
    "        status = 'Passed'\n",
    "        bad_data_summary = 'No missing values in Table'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "        total_bad_rows = len(bad_data_indices)\n",
    "        bad_data_summary = f\"Total missing values: {total_bad_rows}; Rows #: {', '.join(map(str, next_indices))}\"\n",
    "    \n",
    "    # Add validation result to Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = add_validation_result(\n",
    "        Raw_Data_Validation, table_name, dq_check, column_name, status, bad_data_summary, tc_num\n",
    "    )\n",
    "    \n",
    "    # Save the updated Raw_Data_Validation DataFrame to CSV\n",
    "    save_validation_results(Raw_Data_Validation)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "90ccae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_values_source_target(source_csv_path, source_table_name, source_column_name,\n",
    "                           target_folder_path, target_table_name, target_column_name, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform check if all values from source column are present in target column of parquet file and vice versa.\n",
    "    \n",
    "    Arguments:\n",
    "    source_csv_path (str): Path to the source CSV file.\n",
    "    source_table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    source_column_name (str): Name of the source column to check.\n",
    "    target_folder_path (str): Path to the folder containing target Parquet files.\n",
    "    target_table_name (str): Name of the target table (equal to the folder name).\n",
    "    target_column_name (str): Name of the target column to check.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()\n",
    "    \n",
    "    # Read source CSV file into a DataFrame\n",
    "    source_df = pd.read_csv(source_csv_path, keep_default_na=False)\n",
    "\n",
    "    # Load Parquet files from the specified target folder and concatenate them into one DataFrame\n",
    "    target_df = pd.concat([pq.read_table(os.path.join(target_folder_path, f)).to_pandas() \n",
    "                           for f in os.listdir(target_folder_path) if f.endswith('.parquet')],\n",
    "                          ignore_index=True)\n",
    "    \n",
    "    # Check if all source column values are present in target column\n",
    "    source_values_set = set(source_df[source_column_name])\n",
    "    target_values_set = set(target_df[target_column_name])\n",
    "  \n",
    "  \n",
    "    if source_values_set.issubset(target_values_set) and target_values_set.issubset(source_values_set):\n",
    "        status = 'Passed'\n",
    "        bad_data_summary = 'Same values in Source and Target'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "        source_missing_values = sorted(list(source_values_set - target_values_set))\n",
    "        target_missing_values = sorted(list(target_values_set - source_values_set))\n",
    "        \n",
    "        source_missing_str = \", \".join(f\"'{val}'\" for val in source_missing_values) if source_missing_values else ''\n",
    "        target_missing_str = \", \".join(f\"'{val}'\" for val in target_missing_values) if target_missing_values else ''\n",
    "        \n",
    "        if source_missing_str and target_missing_str:\n",
    "            bad_data_summary = (\n",
    "                f\"Total rows with bad data: {len(source_missing_values) + len(target_missing_values)}; \"\n",
    "                f\"Missing in Target: {source_missing_str}; Missing in Source: {target_missing_str}\"\n",
    "            )\n",
    "        elif source_missing_str:\n",
    "            bad_data_summary = f\"Total rows with bad data: {len(source_missing_values)}; Missing in Target: {source_missing_str}\"\n",
    "        elif target_missing_str:\n",
    "            bad_data_summary = f\"Total rows with bad data: {len(target_missing_values)}; Missing in Source: {target_missing_str}\"\n",
    "        else:\n",
    "            bad_data_summary = 'Same values in Source and Target'\n",
    "    \n",
    "    # Add validation result to Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = add_validation_result(\n",
    "        Raw_Data_Validation, [source_table_name, target_table_name], dq_check, [source_column_name, target_column_name], status, bad_data_summary, tc_num\n",
    "    )\n",
    "    \n",
    "    # Save the updated Raw_Data_Validation DataFrame to CSV\n",
    "    save_validation_results(Raw_Data_Validation)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "05d7a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_row_counts(source_csv_path, source_table_name, target_folder_path, target_table_name, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform row count comparison between source CSV file and target Parquet files.\n",
    "    \n",
    "    Arguments:\n",
    "    source_csv_path (str): Path to the source CSV file.\n",
    "    source_table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    target_folder_path (str): Path to the folder containing target Parquet files.\n",
    "    target_table_name (str): Name of the target table (equal to the folder name).\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()\n",
    "    \n",
    "    # Read source CSV file into a DataFrame\n",
    "    source_df = pd.read_csv(source_csv_path, keep_default_na=False)\n",
    "    \n",
    "    # Count rows in source DataFrame\n",
    "    source_row_count = len(source_df)\n",
    "    \n",
    "    # Count rows in target Parquet files\n",
    "    target_row_count = sum(pq.read_table(os.path.join(target_folder_path, f)).to_pandas().shape[0]\n",
    "                           for f in os.listdir(target_folder_path) if f.endswith('.parquet'))\n",
    "    \n",
    "    # Compare row counts between source and target\n",
    "    if source_row_count == target_row_count:\n",
    "        status = 'Passed'\n",
    "        bad_data_summary = 'Same Row counts in Source and Target'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "        bad_data_summary = f\"Source row counts: {source_row_count}; Target row counts: {target_row_count}\"\n",
    "    \n",
    "    # Add validation result to Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = add_validation_result(\n",
    "        Raw_Data_Validation, target_table_name, dq_check, '', status, bad_data_summary, tc_num\n",
    "    )\n",
    "    \n",
    "    # Save the updated Raw_Data_Validation DataFrame to CSV\n",
    "    save_validation_results(Raw_Data_Validation)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "bc17fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_duplicates_csv(source_csv_path, table_name, columns, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform duplicate check in the source CSV file based on specified columns.\n",
    "    \n",
    "    Arguments:\n",
    "    source_csv_path (str): Path to the source CSV file.\n",
    "    source_table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    columns (list of str): List of column names to check for duplicates.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read source CSV file into a DataFrame\n",
    "    source_df = pd.read_csv(source_csv_path, keep_default_na=False)\n",
    "\n",
    "    # Call check_for_duplicates function to perform check and save results into the Raw_Data_Validation\n",
    "    check_for_duplicates(source_df, table_name, columns, dq_check, tc_num)\n",
    "    \n",
    "    return\n",
    "\n",
    "def check_for_duplicates_parquet(target_path, table_name, columns, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform duplicate check in the target parquet file based on specified columns.\n",
    "    \n",
    "    Arguments:\n",
    "    target_path (str): Path to the target parquet file.\n",
    "    target_table_name (str): Name of the target table.\n",
    "    columns (list of str): List of column names to check for duplicates.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load Parquet files from the specified target folder and concatenate them into one DataFrame\n",
    "    target_df = pd.concat([pq.read_table(os.path.join(target_folder_path, f)).to_pandas() \n",
    "                           for f in os.listdir(target_folder_path) if f.endswith('.parquet')],\n",
    "                          ignore_index=True)    \n",
    "    \n",
    "    # Call check_for_duplicates function to perform check and save results into the Raw_Data_Validation\n",
    "    check_for_duplicates(target_df, table_name, columns, dq_check, tc_num)\n",
    "    \n",
    "    return    \n",
    "    \n",
    "def check_for_duplicates(table_df, table_name, columns, dq_check, tc_num):    \n",
    "\n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()\n",
    "    \n",
    "    # Check for duplicates based on specified columns\n",
    "    duplicate_rows = table_df.duplicated(subset=columns, keep=False)\n",
    "    duplicate_indices = table_df[duplicate_rows].index.tolist()\n",
    "    num_duplicate_rows = len(duplicate_indices)\n",
    "    \n",
    "    # Get next indices (index + 1) for duplicate rows to start from 1\n",
    "    next_indices = [idx + 1 for idx in duplicate_indices]    \n",
    "    \n",
    "    # Determine status based on duplicate check\n",
    "    if num_duplicate_rows == 0:\n",
    "        status = 'Passed'\n",
    "        bad_data_summary = 'No duplicates'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "        bad_data_summary =  f\"Duplicates: {num_duplicate_rows}; Duplicate Row Indices: {', '.join(map(str, next_indices))}\"\n",
    "    \n",
    "    # Add validation result to Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = add_validation_result(\n",
    "        Raw_Data_Validation, table_name, dq_check, columns, status, bad_data_summary, tc_num\n",
    "    )\n",
    "    \n",
    "    # Save the updated Raw_Data_Validation DataFrame to CSV\n",
    "    save_validation_results(Raw_Data_Validation)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "71ded076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_state_consistency_csv(table_path, table_name, state_column, country_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform state consistency check based on country for the airport table (airport.csv).\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the source CSV file.\n",
    "    table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    state_column (str): Name of the 'state' column in the airport table.\n",
    "    country_column (str): Name of the 'country' column in the airport table.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "  \n",
    "    # Read airport CSV file into a DataFrame\n",
    "    source_df = pd.read_csv(table_path, keep_default_na=False)\n",
    "    \n",
    "    # Call check_state_consistency function to perform check and save results into the Raw_Data_Validation\n",
    "    check_state_consistency(source_df, table_name, state_column, country_column, dq_check, tc_num)\n",
    "    \n",
    "    return     \n",
    "\n",
    "def check_state_consistency_parquet(table_path, table_name, state_column, country_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform state consistency check based on country for the target parquet file.\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the  target parquet file.\n",
    "    table_name (str): Name of the target parquet file.\n",
    "    state_column (str): Name of the 'state' column in the airport table.\n",
    "    country_column (str): Name of the 'country' column in the airport table.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Load Parquet files from the specified target folder and concatenate them into one DataFrame\n",
    "    target_df = pd.concat([pq.read_table(os.path.join(table_path, f)).to_pandas() \n",
    "                           for f in os.listdir(table_path) if f.endswith('.parquet')],\n",
    "                          ignore_index=True)    \n",
    "    \n",
    "    # Call check_state_consistency function to perform check and save results into the Raw_Data_Validation\n",
    "    check_state_consistency(target_df, table_name, state_column, country_column, dq_check, tc_num)\n",
    "    \n",
    "    return     \n",
    "\n",
    "def check_state_consistency(table_df, table_name, state_column, country_column, dq_check, tc_num):\n",
    "    \n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()\n",
    "    \n",
    "    # Sort table_df DataFrame by specified columns in ascending order\n",
    "    sort_columns = ['iata']\n",
    "    table_df = table_df.sort_values(by=sort_columns, ascending=True)\n",
    "\n",
    "    # Reset index of table_df after sorting\n",
    "    table_df = table_df.reset_index(drop=True)     \n",
    "    \n",
    "    # Filter rows where 'state' is 'NA' and country is not 'USA'\n",
    "    incorrect_records = table_df[((table_df[state_column] == 'NA') & (table_df[country_column] == 'USA')) | \n",
    "                                ((table_df[state_column] != 'NA') & (table_df[country_column] != 'USA'))]\n",
    "    num_incorrect_records = len(incorrect_records)\n",
    "    \n",
    "    # Determine status based on state consistency check\n",
    "    if num_incorrect_records == 0:\n",
    "        status = 'Passed'\n",
    "        bad_data_summary = 'No incorrect NA values'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "      # Convert 'iata' values to strings in quotes and join them into a comma-separated string\n",
    "        incorrect_iata_values = ', '.join([\"'{}'\".format(str(val)) for val in incorrect_records['iata'].tolist()])\n",
    "        bad_data_summary = f\"Number of incorrect records: {num_incorrect_records}; Incorrect records 'iata': {incorrect_iata_values}\"\n",
    "    \n",
    "    # Add validation result to Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = add_validation_result(\n",
    "        Raw_Data_Validation, table_name, dq_check, [state_column, country_column], status, bad_data_summary, tc_num\n",
    "    )\n",
    "    \n",
    "    # Save the updated Raw_Data_Validation DataFrame to CSV\n",
    "    save_validation_results(Raw_Data_Validation)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d25963f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_state_usa_csv(table_path, table_name, state_column, country_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform missing 'state' check for the 'USA' country in the airports table (airports.csv).\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the source CSV file (airports.csv).\n",
    "    table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    state_column (str): Name of the 'state' column in the airport table.\n",
    "    country_column (str): Name of the 'country' column in the airport table.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Read airport CSV file into a DataFrame\n",
    "    source_df = pd.read_csv(table_path, keep_default_na=False)\n",
    "    \n",
    "    # Call check_missing_state_usa function to perform check and save results into the Raw_Data_Validation\n",
    "    check_missing_state_usa(source_df, table_name, state_column, country_column, dq_check, tc_num)\n",
    "    \n",
    "    return     \n",
    "\n",
    "def check_missing_state_usa_parquet(table_path, table_name, state_column, country_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform missing 'state' check for the 'USA' country in the airports parquet file.\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the target parquet file (airports).\n",
    "    table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    state_column (str): Name of the 'state' column in the airport table.\n",
    "    country_column (str): Name of the 'country' column in the airport table.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Load Parquet files from the specified target folder and concatenate them into one DataFrame\n",
    "    target_df = pd.concat([pq.read_table(os.path.join(table_path, f)).to_pandas() \n",
    "                           for f in os.listdir(table_path) if f.endswith('.parquet')],\n",
    "                          ignore_index=True)    \n",
    "    \n",
    "    # Call check_missing_state_usa function to perform check and save results into the Raw_Data_Validation\n",
    "    check_missing_state_usa(target_df, table_name, state_column, country_column, dq_check, tc_num)\n",
    "    \n",
    "    return     \n",
    "\n",
    "def check_missing_state_usa(table_df, table_name, state_column, country_column, dq_check, tc_num):\n",
    "\n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()\n",
    "    \n",
    "    # Sort table_df DataFrame by specified columns in ascending order\n",
    "    sort_columns = ['iata']\n",
    "    table_df = table_df.sort_values(by=sort_columns, ascending=True)\n",
    "\n",
    "    # Reset index of table_df after sorting\n",
    "    table_df = table_df.reset_index(drop=True)     \n",
    "    \n",
    "    # Filter rows where 'state' is missing or 'NA' for the 'USA' country\n",
    "    missing_state_records = table_df[((table_df[state_column] == '') & (table_df[country_column] == 'USA')) |\n",
    "                                      ((table_df[state_column] == 'NA') & (table_df[country_column] == 'USA'))]\n",
    "    num_missing_state_records = len(missing_state_records)\n",
    "    \n",
    "    # Determine status based on missing state check\n",
    "    if num_missing_state_records == 0:\n",
    "        status = 'Passed'\n",
    "        bad_data_summary = 'No missing or NA states for the USA country'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "      # Convert 'iata' values to strings in quotes and join them into a comma-separated string\n",
    "        missing_iata_values = ', '.join([\"'{}'\".format(str(val)) for val in missing_state_records['iata'].tolist()])\n",
    "        bad_data_summary = f\"Number of incorrect records: {num_missing_state_records}; Incorrect records 'iata': {missing_iata_values}\"\n",
    "    \n",
    "    # Add validation result to Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = add_validation_result(\n",
    "        Raw_Data_Validation, table_name, dq_check, [state_column, country_column], status, bad_data_summary, tc_num\n",
    "    )\n",
    "    \n",
    "    # Save the updated Raw_Data_Validation DataFrame to CSV\n",
    "    save_validation_results(Raw_Data_Validation)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "85e18c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of valid US state abbreviations\n",
    "valid_state_abbreviations = [\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS',\n",
    "    'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY',\n",
    "    'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'\n",
    "]\n",
    "\n",
    "def check_valid_state_abbreviations_csv(table_path, table_name, state_column, country_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform state abbreviation check for rows with 'USA' country in the airport table (airports.csv).\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the source CSV file (airports.csv).\n",
    "    table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    state_column (str): Name of the 'state' column in the airport table.\n",
    "    country_column (str): Name of the 'country' column in the airport table.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Read airport CSV file into a DataFrame\n",
    "    source_df = pd.read_csv(table_path, keep_default_na=False)\n",
    "    \n",
    "    # Call check_missing_state_usa function to perform check and save results into the Raw_Data_Validation\n",
    "    check_valid_state_abbreviations(source_df, table_name, state_column, country_column, dq_check, tc_num)\n",
    "    \n",
    "    return     \n",
    "\n",
    "def check_valid_state_abbreviations_parquet(table_path, table_name, state_column, country_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform state abbreviation check for rows with 'USA' country in the airports parquet file.\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the target parquet file (airports).\n",
    "    table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    state_column (str): Name of the 'state' column in the airport table.\n",
    "    country_column (str): Name of the 'country' column in the airport table.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Load Parquet files from the specified target folder and concatenate them into one DataFrame\n",
    "    target_df = pd.concat([pq.read_table(os.path.join(table_path, f)).to_pandas() \n",
    "                           for f in os.listdir(table_path) if f.endswith('.parquet')],\n",
    "                          ignore_index=True)    \n",
    "    \n",
    "    # Call check_valid_state_abbreviations function to perform check and save results into the Raw_Data_Validation\n",
    "    check_valid_state_abbreviations(target_df, table_name, state_column, country_column, dq_check, tc_num)\n",
    "    \n",
    "    return  \n",
    "\n",
    "def check_valid_state_abbreviations(table_df, table_name, state_column, country_column, dq_check, tc_num):\n",
    "\n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()\n",
    "\n",
    "    # Sort table_df DataFrame by specified columns in ascending order\n",
    "    sort_columns = ['iata']\n",
    "    table_df = table_df.sort_values(by=sort_columns, ascending=True)\n",
    "\n",
    "    # Reset index of table_df after sorting\n",
    "    table_df = table_df.reset_index(drop=True)     \n",
    "    \n",
    "    # Filter rows where 'country' is 'USA'\n",
    "    usa_records = table_df[table_df[country_column] == 'USA']\n",
    "    \n",
    "    # Filter USA records with invalid state abbreviations\n",
    "    invalid_state_records = usa_records[~usa_records[state_column].isin(valid_state_abbreviations)]\n",
    "    num_invalid_state_records = len(invalid_state_records)\n",
    "    \n",
    "    # Determine status based on state abbreviation check\n",
    "    if num_invalid_state_records == 0:\n",
    "        status = 'Passed'\n",
    "        bad_data_summary = 'No incorrect state abbreviation'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "        # Get list of incorrect state abbreviations\n",
    "        incorrect_abbreviations = invalid_state_records[state_column].tolist()\n",
    "        incorrect_abbreviations_str = ', '.join(incorrect_abbreviations)\n",
    "        bad_data_summary = f\"Incorrect state abbreviation: {num_invalid_state_records}; Incorrect records: {incorrect_abbreviations_str}\"\n",
    "    \n",
    "    # Add validation result to Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = add_validation_result(\n",
    "        Raw_Data_Validation, table_name, dq_check, [state_column, country_column], status, bad_data_summary, tc_num\n",
    "    )\n",
    "    \n",
    "    # Save the updated Raw_Data_Validation DataFrame to CSV\n",
    "    save_validation_results(Raw_Data_Validation)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3dd17ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cancellation_codes_csv(table_path, table_name, cancelled_column, cancellation_code_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform cancellation code check based on the 'Cancelled' column values in the flights table (flights.csv).\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the source CSV file (flights.csv).\n",
    "    table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    cancelled_column (str): Name of the 'Cancelled' column in the flights table.\n",
    "    cancellation_code_column (str): Name of the 'CancellationCode' column in the flights table.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Read airport CSV file into a DataFrame\n",
    "    source_df = pd.read_csv(table_path, keep_default_na=False)\n",
    "    \n",
    "    # Call check_cancellation_codes function to perform check and save results into the Raw_Data_Validation\n",
    "    check_cancellation_codes(source_df, table_name, cancelled_column, cancellation_code_column, dq_check, tc_num)\n",
    "    \n",
    "    return\n",
    "    \n",
    "    \n",
    "def check_cancellation_codes_parquet(table_path, table_name, cancelled_column, cancellation_code_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform cancellation code check based on the 'Cancelled' column values in the flights parquet file.\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the flights parquet file.\n",
    "    table_name (str): Name of the target parquet file.\n",
    "    cancelled_column (str): Name of the 'Cancelled' column in the flights table.\n",
    "    cancellation_code_column (str): Name of the 'CancellationCode' column in the flights table.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Load Parquet files from the specified target folder and concatenate them into one DataFrame\n",
    "    target_df = pd.concat([pq.read_table(os.path.join(table_path, f)).to_pandas() \n",
    "                           for f in os.listdir(table_path) if f.endswith('.parquet')],\n",
    "                          ignore_index=True)    \n",
    "    \n",
    "    # Call check_cancellation_codes function to perform check and save results into the Raw_Data_Validation\n",
    "    check_cancellation_codes(target_df, table_name, cancelled_column, cancellation_code_column, dq_check, tc_num)\n",
    "    \n",
    "    return  \n",
    "\n",
    "\n",
    "def check_cancellation_codes(table_df, table_name, cancelled_column, cancellation_code_column, dq_check, tc_num):\n",
    "\n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()\n",
    "\n",
    "    # Sort table_df DataFrame by specified columns in ascending order\n",
    "    sort_columns = ['Year', 'Month', 'DayofMonth', 'DepTime', 'FlightNum']\n",
    "    table_df = table_df.sort_values(by=sort_columns, ascending=True)\n",
    "\n",
    "    # Reset index of table_df after sorting\n",
    "    table_df = table_df.reset_index(drop=True)     \n",
    "    \n",
    "    # Filter rows with incorrect cancellation codes based on business rules\n",
    "    incorrect_records = table_df[\n",
    "        ((table_df[cancelled_column] == '1') & ~table_df[cancellation_code_column].isin(['A', 'B', 'C'])) |\n",
    "        ((table_df[cancelled_column] == '0') & (table_df[cancellation_code_column] != ''))\n",
    "    ]\n",
    "    \n",
    "    num_incorrect_records = len(incorrect_records)\n",
    "    \n",
    "    # Determine status based on cancellation code check\n",
    "    if num_incorrect_records == 0:\n",
    "        status = 'Passed'\n",
    "        bad_data_summary = 'No incorrect values'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "        # Get list of row numbers with incorrect cancellation codes\n",
    "        incorrect_indices = incorrect_records.index.tolist()\n",
    "        # Adjust row indices to start counting from 1\n",
    "        incorrect_indices = [idx + 1 for idx in incorrect_indices]\n",
    "        bad_data_summary = (\n",
    "            f\"Number of incorrect records: {num_incorrect_records}; \"\n",
    "            f\"Rows with bad data: {', '.join(map(str, incorrect_indices))}\"\n",
    "        )   \n",
    "    \n",
    "    # Add validation result to Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = add_validation_result(\n",
    "        Raw_Data_Validation, table_name, dq_check, [cancelled_column, cancellation_code_column], status, bad_data_summary, tc_num\n",
    "    )\n",
    "    \n",
    "    # Save the updated Raw_Data_Validation DataFrame to CSV\n",
    "    save_validation_results(Raw_Data_Validation)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a8c59fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_elapsed_time_calculation_csv(\n",
    "        table_path, table_name, elapsed_time_column, arr_time_column, dep_time_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform CRSElapsedTime calculation check based on 'CRSArrTime' and 'CRSDepTime' columns in the flights table (flights.csv).\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the source CSV file (flights.csv).\n",
    "    table_name (str): Name of the source table (equal to the CSV file name).\n",
    "    elapsed_time_column (str): Name of the 'CRSElapsedTime' column in the flights table.\n",
    "    arr_time_column (str): Name of the 'CRSArrTime' (Scheduled arrival time) column.\n",
    "    dep_time_column (str): Name of the 'CRSDepTime' (Scheduled departure time) column.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Read airport CSV file into a DataFrame\n",
    "    source_df = pd.read_csv(table_path, keep_default_na=False)\n",
    "    \n",
    "    # Call check_elapsed_time_calculation function to perform check and save results into the Raw_Data_Validation\n",
    "    check_elapsed_time_calculation(source_df, table_name, elapsed_time_column, arr_time_column, dep_time_column, dq_check, tc_num)\n",
    "    \n",
    "    return\n",
    "    \n",
    "    \n",
    "def check_elapsed_time_calculation_parquet(\n",
    "        table_path, table_name, elapsed_time_column, arr_time_column, dep_time_column, dq_check, tc_num):\n",
    "    \"\"\"\n",
    "    Perform CRSElapsedTime calculation check based on 'CRSArrTime' and 'CRSDepTime' columns in the flights parquet file.\n",
    "    \n",
    "    Arguments:\n",
    "    table_path (str): Path to the target parquet file (flights).\n",
    "    table_name (str): Name of the target parquet file.\n",
    "    elapsed_time_column (str): Name of the 'CRSElapsedTime' column in the flights table.\n",
    "    arr_time_column (str): Name of the 'CRSArrTime' (Scheduled arrival time) column.\n",
    "    dep_time_column (str): Name of the 'CRSDepTime' (Scheduled departure time) column.\n",
    "    dq_check (str): Name of the data quality check.\n",
    "    tc_num (str): Test Case number.    \n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated Raw_Data_Validation DataFrame with the validation results.\n",
    "    \"\"\"\n",
    "    # Load Parquet files from the specified target folder and concatenate them into one DataFrame\n",
    "    target_df = pd.concat([pq.read_table(os.path.join(table_path, f)).to_pandas() \n",
    "                           for f in os.listdir(table_path) if f.endswith('.parquet')],\n",
    "                          ignore_index=True)    \n",
    "    \n",
    "    # Call check_elapsed_time_calculation function to perform check and save results into the Raw_Data_Validation\n",
    "    check_elapsed_time_calculation(target_df, table_name, elapsed_time_column, arr_time_column, dep_time_column, dq_check, tc_num)\n",
    "    \n",
    "    return  \n",
    "\n",
    "\n",
    "def convert_time_to_hhmm(time_str):\n",
    "    \"\"\"\n",
    "    Convert various time string formats to HH:MM format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the time string by removing non-numeric characters\n",
    "        cleaned_time_str = ''.join(filter(str.isdigit, time_str))\n",
    "\n",
    "        # Ensure the cleaned time string has at least four digits (HHMM format)\n",
    "        cleaned_time_str = cleaned_time_str.zfill(4)\n",
    "\n",
    "        # Extract hours and minutes\n",
    "        hours = int(cleaned_time_str[:2])\n",
    "        minutes = int(cleaned_time_str[2:])\n",
    "\n",
    "        # Validate hours and minutes ranges (0-23 for hours, 0-59 for minutes)\n",
    "        if 0 <= hours <= 23 and 0 <= minutes <= 59:\n",
    "            # Format as HH:MM\n",
    "            formatted_time = f'{hours:02}:{minutes:02}'\n",
    "            return formatted_time\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid time format: {time_str}\")\n",
    "    except Exception as e:\n",
    "        # Handle any errors during time conversion\n",
    "        print(f\"Error converting time '{time_str}': {e}\")\n",
    "        return None  # Return None for invalid or unexpected inputs  \n",
    "    \n",
    "    \n",
    "def check_elapsed_time_calculation(\n",
    "    table_df, table_name, elapsed_time_column, arr_time_column, dep_time_column, dq_check, tc_num):\n",
    "\n",
    "    # Initialize or load the Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = initialize_validation_dataframe()  \n",
    "    \n",
    "    # Sort table_df DataFrame by specified columns in ascending order\n",
    "    sort_columns = ['Year', 'Month', 'DayofMonth', 'DepTime', 'FlightNum']\n",
    "    table_df = table_df.sort_values(by=sort_columns, ascending=True)\n",
    "\n",
    "    # Reset index of table_df after sorting\n",
    "    table_df = table_df.reset_index(drop=True)    \n",
    "    \n",
    "    # Convert time columns to HH:MM format\n",
    "    table_df[arr_time_column] = table_df[arr_time_column].apply(convert_time_to_hhmm)\n",
    "    table_df[dep_time_column] = table_df[dep_time_column].apply(convert_time_to_hhmm)\n",
    "    \n",
    "    # Calculate expected CRSElapsedTime and round to nearest whole number\n",
    "    table_df['expected_elapsed_time'] = (\n",
    "        pd.to_datetime(table_df[arr_time_column], format='%H:%M') -\n",
    "        pd.to_datetime(table_df[dep_time_column], format='%H:%M')\n",
    "    ).dt.total_seconds() / 60\n",
    "    \n",
    "    table_df['expected_elapsed_time'] = table_df['expected_elapsed_time'].round()\n",
    "    \n",
    "    # Convert existing CRSElapsedTime column to numeric type\n",
    "    table_df[elapsed_time_column] = pd.to_numeric(table_df[elapsed_time_column], errors='coerce')\n",
    "    \n",
    "    # Compare expected CRSElapsedTime with recorded CRSElapsedTime\n",
    "    table_df['is_elapsed_time_correct'] = table_df[elapsed_time_column] == table_df['expected_elapsed_time']      \n",
    "    \n",
    "    # Filter out rows with incorrect CRSElapsedTime\n",
    "    incorrect_records = table_df[~table_df['is_elapsed_time_correct']]\n",
    "    num_incorrect_records = len(incorrect_records)\n",
    "    \n",
    "    # Determine status based on CRSElapsedTime consistency check\n",
    "    if num_incorrect_records == 0:\n",
    "        status = 'Passed'\n",
    "        bad_data_summary = 'No incorrect records'\n",
    "    else:\n",
    "        status = 'Failed'\n",
    "        # Get list of row numbers with correct CRSElapsedTime\n",
    "        incorrect_indices = incorrect_records.index.tolist()\n",
    "        # Adjust row indices to start counting from 1\n",
    "        incorrect_indices = [idx + 1 for idx in incorrect_indices]\n",
    "        bad_data_summary = (\n",
    "            f\"Number of incorrect records: {num_incorrect_records}; \"\n",
    "            f\"Rows #: {', '.join(map(str, incorrect_indices))}\"        \n",
    "        )\n",
    "    \n",
    "    # Add validation result to Raw_Data_Validation DataFrame\n",
    "    Raw_Data_Validation = add_validation_result(\n",
    "        Raw_Data_Validation, table_name, dq_check, [elapsed_time_column, arr_time_column, dep_time_column],\n",
    "        status, bad_data_summary, tc_num\n",
    "    )\n",
    "    \n",
    "    # Save the updated Raw_Data_Validation DataFrame to CSV\n",
    "    save_validation_results(Raw_Data_Validation)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "50e10007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num</th>\n",
       "      <th>Table</th>\n",
       "      <th>DQ check</th>\n",
       "      <th>Column</th>\n",
       "      <th>Status</th>\n",
       "      <th>Bad Data</th>\n",
       "      <th>Test Case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Num, Table, DQ check, Column, Status, Bad Data, Test Case]\n",
       "Index: []"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare Raw_Data_Validation DataFrame\n",
    "drop_validation_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "bc4701d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #1:\n",
    "\n",
    "# Check that no NULL and empty values in the 'code' PK column of the source 'carriers' table \n",
    "\n",
    "# Initial parameters:\n",
    "folder_path = csv_carriers\n",
    "table_name = 'carriers.csv'\n",
    "dq_check = 'Completeness'\n",
    "column_name = 'Code'\n",
    "tc_num = 'TC #1'\n",
    "\n",
    "# Perform completeness check and store results in Raw_Data_Validation DataFrame\n",
    "check_null_values_csv(folder_path, table_name, dq_check, column_name, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3f102271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #2:\n",
    "\n",
    "# Check that no NULL and empty values in the 'Description' PK column of the source 'carriers' table \n",
    "\n",
    "# Initial parameters:\n",
    "folder_path = csv_carriers\n",
    "table_name = 'carriers.csv'\n",
    "dq_check = 'Completeness'\n",
    "column_name = 'Description'\n",
    "tc_num = 'TC #2'\n",
    "\n",
    "# Perform completeness check and store results in Raw_Data_Validation DataFrame\n",
    "check_null_values_csv(folder_path, table_name, dq_check, column_name, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "344fe05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #3:\n",
    "\n",
    "# Check that no NULL and empty values in the 'code' PK column of the target 'carriers' table \n",
    "\n",
    "# Initial parameters:\n",
    "folder_path = parquet_carriers\n",
    "table_name = 'carriers'\n",
    "dq_check = 'Completeness'\n",
    "column_name = 'code'\n",
    "tc_num = 'TC #3'\n",
    "\n",
    "# Perform completeness check and store results in Raw_Data_Validation DataFrame\n",
    "check_null_values_parquet(folder_path, table_name, dq_check, column_name, tc_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "57152296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #4:\n",
    "\n",
    "# Check that no NULL and empty values in the 'description' PK column of the target 'carriers' table \n",
    "\n",
    "# Initial parameters:\n",
    "dq_check = 'Completeness'\n",
    "folder_path = parquet_carriers\n",
    "table_name = 'carriers'\n",
    "column_name = 'description'\n",
    "tc_num = 'TC #4'\n",
    "\n",
    "# Perform completeness check and store results in Raw_Data_Validation DataFrame\n",
    "check_null_values_parquet(folder_path, table_name, dq_check, column_name, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "06ab1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #5:\n",
    "\n",
    "# Check that all values from source table are present in target table correspondent column, no data gaps\n",
    "\n",
    "# Initial parameters:\n",
    "dq_check = 'Completeness'\n",
    "source_csv_path = csv_carriers\n",
    "source_table_name = 'carriers.csv'\n",
    "source_column_name = 'Code'\n",
    "target_folder_path = parquet_carriers\n",
    "target_table_name = 'carriers'\n",
    "target_column_name = 'code'\n",
    "tc_num = 'TC #5'\n",
    "\n",
    "# Perform completeness check on values in the source and target column 'code'\n",
    "compare_values_source_target(source_csv_path, source_table_name, source_column_name,\n",
    "                       target_folder_path, target_table_name, target_column_name, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "51ac69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #6:\n",
    "\n",
    "# Check that all values from source table are present in target table correspondent column, no data gaps\n",
    "\n",
    "# Initial parameters:\n",
    "source_csv_path = csv_carriers\n",
    "source_table_name = 'carriers.csv'\n",
    "source_column_name = 'Description'\n",
    "target_folder_path = parquet_carriers\n",
    "target_table_name = 'carriers'\n",
    "target_column_name = 'description'\n",
    "dq_check = 'Completeness'\n",
    "tc_num = 'TC #6'\n",
    "\n",
    "# Perform completeness check on values in the source and target column 'description'\n",
    "compare_values_source_target(source_csv_path, source_table_name, source_column_name,\n",
    "                       target_folder_path, target_table_name, target_column_name, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b3515618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #7:\n",
    "\n",
    "# Check that row counts in source and target tables are equal\n",
    "\n",
    "# Initial parameters:\n",
    "source_csv_path = csv_carriers\n",
    "source_table_name = 'carriers.csv'\n",
    "target_folder_path = parquet_carriers\n",
    "target_table_name = 'carriers, carriers.csv'\n",
    "dq_check = 'Completeness'\n",
    "tc_num = 'TC #7'\n",
    "\n",
    "# Perform row count comparison between source and target\n",
    "compare_row_counts(source_csv_path, source_table_name, target_folder_path, target_table_name, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9afc1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #8:\n",
    "\n",
    "# Check that no duplicate values in source table\n",
    "\n",
    "# Initial parameters:\n",
    "source_csv_path = csv_carriers\n",
    "table_name = 'carriers.csv'\n",
    "columns_to_check = ['Code', 'Description']\n",
    "dq_check = 'Completeness'\n",
    "tc_num = 'TC #8'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_for_duplicates_csv(source_csv_path, table_name, columns_to_check, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1accaf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #9:\n",
    "\n",
    "# Check that no duplicate values in target table\n",
    "\n",
    "# Initial parameters:\n",
    "target_path = parquet_carriers\n",
    "table_name = 'carriers'\n",
    "columns_to_check = ['code', 'description']\n",
    "dq_check = 'Completeness'\n",
    "tc_num = 'TC #9'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_for_duplicates_parquet(target_path, table_name, columns_to_check, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6f90e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #10:\n",
    "\n",
    "# Source table 'airports.csv'\n",
    "# Check that no 'NA' values in the state column for the 'USA' country\n",
    "# and 'NA' values in the state column for each non 'USA' country\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = csv_airports\n",
    "table_name = 'airports.csv'\n",
    "state_column = 'state'\n",
    "country_column = 'country'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #10'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_state_consistency_csv(table_path, table_name, state_column, country_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c369302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #11:\n",
    "\n",
    "# Target table 'airports', parquet\n",
    "# Check that no 'NA' values in the state column for the 'USA' country\n",
    "# and 'NA' values in the state column for each non 'USA' country\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = parquet_airports\n",
    "table_name = 'airports'\n",
    "state_column = 'state'\n",
    "country_column = 'country'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #11'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_state_consistency_parquet(table_path, table_name, state_column, country_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e8e3df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #12:\n",
    "\n",
    "# Source table 'airports.csv'\n",
    "# Check that State specified for all records where country 'USA' in source table\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = csv_airports\n",
    "table_name = 'airports.csv'\n",
    "state_column = 'state'\n",
    "country_column = 'country'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #12'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_missing_state_usa_csv(table_path, table_name, state_column, country_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c1bedd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #13:\n",
    "\n",
    "# Target table 'airports', parquet\n",
    "# Check that State specified for all records where country 'USA' in target table\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = parquet_airports\n",
    "table_name = 'airports'\n",
    "state_column = 'state'\n",
    "country_column = 'country'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #13'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_missing_state_usa_parquet(table_path, table_name, state_column, country_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a531177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #14:\n",
    "\n",
    "# Compare values in source and target table for the 'state' column\n",
    "# Initial parameters:\n",
    "source_csv_path = csv_airports\n",
    "source_table_name = 'airports.csv'\n",
    "source_column_name = 'state'\n",
    "target_folder_path = parquet_airports\n",
    "target_table_name = 'airports'\n",
    "target_column_name = 'state'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #14'\n",
    "\n",
    "# Perform completeness check on values in the source and target column 'state'\n",
    "compare_values_source_target(source_csv_path, source_table_name, source_column_name,\n",
    "                       target_folder_path, target_table_name, target_column_name, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "765c4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #15:  (optional for the Consistency checks)\n",
    "\n",
    "# Source table 'airports.csv'\n",
    "# Check that abbreviation in the state column for the 'USA' country is correct\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = csv_airports\n",
    "table_name = 'airports.csv'\n",
    "state_column = 'state'\n",
    "country_column = 'country'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #15'\n",
    "\n",
    "# Perform abbreviation check based on specified columns\n",
    "check_valid_state_abbreviations_csv(table_path, table_name, state_column, country_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ebca3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #16:  (optional for the Consistency checks)\n",
    "\n",
    "# Source table 'airports'\n",
    "# Check that abbreviation in the state column for the 'USA' country is correct\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = parquet_airports\n",
    "table_name = 'airports'\n",
    "state_column = 'state'\n",
    "country_column = 'country'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #16'\n",
    "\n",
    "# Perform abbreviation check based on specified columns\n",
    "check_valid_state_abbreviations_parquet(table_path, table_name, state_column, country_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a36b85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #17:\n",
    "\n",
    "# Source table 'flights.csv'\n",
    "# Check if 'Cancelled' is 0 then CancellationCode is NULL\n",
    "# and if 'Cancelled' is 1 then CancellationCode in the ['A', 'B', 'C']\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = csv_flights\n",
    "table_name = 'flights.csv'\n",
    "cancelled_column = 'Cancelled'\n",
    "cancellation_code_column = 'CancellationCode'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #17'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_cancellation_codes_csv(table_path, table_name, cancelled_column, cancellation_code_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e6ef43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #18:\n",
    "\n",
    "# Target table 'flights', parquet\n",
    "# Check if 'Cancelled' is 0 then CancellationCode is NULL\n",
    "# and if 'Cancelled' is 1 then CancellationCode in the ['A', 'B', 'C']\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = parquet_flights\n",
    "table_name = 'flights'\n",
    "cancelled_column = 'Cancelled'\n",
    "cancellation_code_column = 'CancellationCode'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #18'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_cancellation_codes_parquet(table_path, table_name, cancelled_column, cancellation_code_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "dbb58418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #19:\n",
    "\n",
    "# Compare values in source and target table for the 'CancellationCode' column\n",
    "# Initial parameters:\n",
    "source_csv_path = csv_flights\n",
    "source_table_name = 'flights.csv'\n",
    "source_column_name = 'CancellationCode'\n",
    "target_folder_path = parquet_flights\n",
    "target_table_name = 'flights'\n",
    "target_column_name = 'CancellationCode'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #19'\n",
    "\n",
    "# Perform consistency check on values in the source and target column 'CancellationCode'\n",
    "compare_values_source_target(source_csv_path, source_table_name, source_column_name,\n",
    "                       target_folder_path, target_table_name, target_column_name, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b689a15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting time '870': Invalid time format: 870\n",
      "Error converting time '1275': Invalid time format: 1275\n"
     ]
    }
   ],
   "source": [
    "# DQ_CHECK #20:\n",
    "\n",
    "# Source table 'flights.csv'\n",
    "# Check that CRSElapsedTime column values are calculated correctly\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = csv_flights\n",
    "table_name = 'flights.csv'\n",
    "elapsed_time_column = 'CRSElapsedTime'\n",
    "arr_time_column = 'CRSArrTime'\n",
    "dep_time_column = 'CRSDepTime'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #20'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_elapsed_time_calculation_csv(\n",
    "    table_path, table_name, elapsed_time_column, arr_time_column, dep_time_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c4c0cd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting time '870': Invalid time format: 870\n",
      "Error converting time '1275': Invalid time format: 1275\n"
     ]
    }
   ],
   "source": [
    "# DQ_CHECK #21:\n",
    "\n",
    "# Target table 'flights', parquet\n",
    "# Check that CRSElapsedTime column values are calculated correctly\n",
    "\n",
    "# Initial parameters:\n",
    "table_path = parquet_flights\n",
    "table_name = 'flights'\n",
    "elapsed_time_column = 'CRSElapsedTime'\n",
    "arr_time_column = 'CRSArrTime'\n",
    "dep_time_column = 'CRSDepTime'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #21'\n",
    "\n",
    "# Perform duplicate check based on specified columns\n",
    "check_elapsed_time_calculation_parquet(\n",
    "    table_path, table_name, elapsed_time_column, arr_time_column, dep_time_column, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "fdbcfef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQ_CHECK #22:\n",
    "\n",
    "# Compare values in source and target table for the 'CRSElapsedTime' column\n",
    "# Initial parameters:\n",
    "source_csv_path = csv_flights\n",
    "source_table_name = 'flights.csv'\n",
    "source_column_name = 'CRSElapsedTime'\n",
    "target_folder_path = parquet_flights\n",
    "target_table_name = 'flights'\n",
    "target_column_name = 'CRSElapsedTime'\n",
    "dq_check = 'Consistency'\n",
    "tc_num = 'TC #22'\n",
    "\n",
    "# Perform consistency check on values in the source and target column 'CRSElapsedTime'\n",
    "compare_values_source_target(source_csv_path, source_table_name, source_column_name,\n",
    "                       target_folder_path, target_table_name, target_column_name, dq_check, tc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a8905789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num</th>\n",
       "      <th>Table</th>\n",
       "      <th>DQ check</th>\n",
       "      <th>Column</th>\n",
       "      <th>Status</th>\n",
       "      <th>Bad Data</th>\n",
       "      <th>Test Case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>carriers.csv</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>Code</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Total missing values: 4; Rows #: 8, 36, 52, 79</td>\n",
       "      <td>TC #1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>carriers.csv</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>Description</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Total missing values: 3; Rows #: 8, 15, 16</td>\n",
       "      <td>TC #2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>carriers</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>code</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Total missing values: 4; Rows #: 8, 36, 52, 79</td>\n",
       "      <td>TC #3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>carriers</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>description</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Total missing values: 3; Rows #: 8, 15, 16</td>\n",
       "      <td>TC #4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['carriers.csv', 'carriers']</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>['Code', 'code']</td>\n",
       "      <td>Passed</td>\n",
       "      <td>Same values in Source and Target</td>\n",
       "      <td>TC #5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>['carriers.csv', 'carriers']</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>['Description', 'description']</td>\n",
       "      <td>Passed</td>\n",
       "      <td>Same values in Source and Target</td>\n",
       "      <td>TC #6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>carriers, carriers.csv</td>\n",
       "      <td>Completeness</td>\n",
       "      <td></td>\n",
       "      <td>Passed</td>\n",
       "      <td>Same Row counts in Source and Target</td>\n",
       "      <td>TC #7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>carriers.csv</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>['Code', 'Description']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Duplicates: 7; Duplicate Row Indices: 5, 7, 1495, 1502, 1503, 1504, 1505</td>\n",
       "      <td>TC #8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>carriers</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>['code', 'description']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Duplicates: 7; Duplicate Row Indices: 5, 7, 1495, 1502, 1503, 1504, 1505</td>\n",
       "      <td>TC #9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>airports.csv</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['state', 'country']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Number of incorrect records: 12; Incorrect records 'iata': '', '01B', '01C', '01D', 'CLD', 'HHH', 'MIB', 'MQT', 'RCA', 'RDR', 'SCE', 'SKA'</td>\n",
       "      <td>TC #10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>airports</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['state', 'country']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Number of incorrect records: 12; Incorrect records 'iata': '', '01B', '01C', '01D', 'CLD', 'HHH', 'MIB', 'MQT', 'RCA', 'RDR', 'SCE', 'SKA'</td>\n",
       "      <td>TC #11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>airports.csv</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['state', 'country']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Number of incorrect records: 9; Incorrect records 'iata': '01A', 'CLD', 'HHH', 'MIB', 'MQT', 'RCA', 'RDR', 'SCE', 'SKA'</td>\n",
       "      <td>TC #12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>airports</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['state', 'country']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Number of incorrect records: 9; Incorrect records 'iata': '01A', 'CLD', 'HHH', 'MIB', 'MQT', 'RCA', 'RDR', 'SCE', 'SKA'</td>\n",
       "      <td>TC #13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>['airports.csv', 'airports']</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['state', 'state']</td>\n",
       "      <td>Passed</td>\n",
       "      <td>Same values in Source and Target</td>\n",
       "      <td>TC #14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>airports.csv</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['state', 'country']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Incorrect state abbreviation: 35; Incorrect records: , DC, PR, PR, NA, PR, AS, CQ, CQ, GU, NA, PR, NA, NA, AS, PR, PR, NA, NA, NA, PR, PR, NA, VI, VI, CQ, CQ, PR, PR, VI, VI, PR, VI, AS, AS</td>\n",
       "      <td>TC #15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>airports</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['state', 'country']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Incorrect state abbreviation: 35; Incorrect records: , DC, PR, PR, NA, PR, AS, CQ, CQ, GU, NA, PR, NA, NA, AS, PR, PR, NA, NA, NA, PR, PR, NA, VI, VI, CQ, CQ, PR, PR, VI, VI, PR, VI, AS, AS</td>\n",
       "      <td>TC #16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>flights.csv</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['Cancelled', 'CancellationCode']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Number of incorrect records: 4; Rows with bad data: 42, 78, 203, 345</td>\n",
       "      <td>TC #17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>flights</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['Cancelled', 'CancellationCode']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Number of incorrect records: 4; Rows with bad data: 42, 78, 203, 345</td>\n",
       "      <td>TC #18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>['flights.csv', 'flights']</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['CancellationCode', 'CancellationCode']</td>\n",
       "      <td>Passed</td>\n",
       "      <td>Same values in Source and Target</td>\n",
       "      <td>TC #19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>flights.csv</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['CRSElapsedTime', 'CRSArrTime', 'CRSDepTime']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Number of incorrect records: 248; Rows #: 1, 2, 3, 4, 5, 6, 7, 8, 12, 16, 17, 18, 19, 21, 22, 29, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 55, 56, 58, 64, 71, 72, 73, 74, 76, 77, 78, 79, 82, 83, 84, 88, 91, 92, 97, 100, 102, 105, 107, 111, 112, 115, 122, 125, 126, 129, 133, 136, 139, 140, 141, 145, 146, 147, 148, 150, 152, 153, 154, 156, 159, 161, 165, 166, 168, 170, 172, 173, 175, 177, 178, 180, 181, 183, 186, 187, 191, 194, 196, 200, 201, 203, 206, 208, 211, 213, 222, 223, 225, 228, 233, 234, 236, 237, 238, 239, 240, 242, 243, 246, 247, 248, 252, 255, 260, 266, 268, 271, 272, 277, 284, 285, 286, 287, 290, 291, 293, 300, 301, 302, 303, 308, 310, 314, 316, 317, 318, 319, 326, 327, 329, 331, 333, 336, 337, 338, 340, 341, 352, 353, 355, 359, 360, 362, 363, 364, 368, 369, 384, 386, 391, 397, 398, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 427, 429, 436, 447, 448, 449, 451, 452, 453, 454, 455, 456, 459, 462, 471, 473, 475, 476, 477, 478, 479, 480, 481, 482, 486, 491, 492, 493, 494, 495, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 519, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532</td>\n",
       "      <td>TC #20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>flights</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['CRSElapsedTime', 'CRSArrTime', 'CRSDepTime']</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Number of incorrect records: 248; Rows #: 1, 2, 3, 4, 5, 6, 7, 8, 12, 16, 17, 18, 19, 21, 22, 29, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 55, 56, 58, 64, 71, 72, 73, 74, 76, 77, 78, 79, 82, 83, 84, 88, 91, 92, 97, 100, 102, 105, 107, 111, 112, 115, 122, 125, 126, 129, 133, 136, 139, 140, 141, 145, 146, 147, 148, 150, 152, 153, 154, 156, 159, 161, 165, 166, 168, 170, 172, 173, 175, 177, 178, 180, 181, 183, 186, 187, 191, 194, 196, 200, 201, 203, 206, 208, 211, 213, 222, 223, 225, 228, 233, 234, 236, 237, 238, 239, 240, 242, 243, 246, 247, 248, 252, 255, 260, 266, 268, 271, 272, 277, 284, 285, 286, 287, 290, 291, 293, 300, 301, 302, 303, 308, 310, 314, 316, 317, 318, 319, 326, 327, 329, 331, 333, 336, 337, 338, 340, 341, 352, 353, 355, 359, 360, 362, 363, 364, 368, 369, 384, 386, 391, 397, 398, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 427, 429, 436, 447, 448, 449, 451, 452, 453, 454, 455, 456, 459, 462, 471, 473, 475, 476, 477, 478, 479, 480, 481, 482, 486, 491, 492, 493, 494, 495, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 519, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532</td>\n",
       "      <td>TC #21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>['flights.csv', 'flights']</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>['CRSElapsedTime', 'CRSElapsedTime']</td>\n",
       "      <td>Passed</td>\n",
       "      <td>Same values in Source and Target</td>\n",
       "      <td>TC #22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Num                         Table      DQ check  \\\n",
       "0     1                  carriers.csv  Completeness   \n",
       "1     2                  carriers.csv  Completeness   \n",
       "2     3                      carriers  Completeness   \n",
       "3     4                      carriers  Completeness   \n",
       "4     5  ['carriers.csv', 'carriers']  Completeness   \n",
       "5     6  ['carriers.csv', 'carriers']  Completeness   \n",
       "6     7        carriers, carriers.csv  Completeness   \n",
       "7     8                  carriers.csv  Completeness   \n",
       "8     9                      carriers  Completeness   \n",
       "9    10                  airports.csv   Consistency   \n",
       "10   11                      airports   Consistency   \n",
       "11   12                  airports.csv   Consistency   \n",
       "12   13                      airports   Consistency   \n",
       "13   14  ['airports.csv', 'airports']   Consistency   \n",
       "14   15                  airports.csv   Consistency   \n",
       "15   16                      airports   Consistency   \n",
       "16   17                   flights.csv   Consistency   \n",
       "17   18                       flights   Consistency   \n",
       "18   19    ['flights.csv', 'flights']   Consistency   \n",
       "19   20                   flights.csv   Consistency   \n",
       "20   21                       flights   Consistency   \n",
       "21   22    ['flights.csv', 'flights']   Consistency   \n",
       "\n",
       "                                            Column  Status  \\\n",
       "0                                             Code  Failed   \n",
       "1                                      Description  Failed   \n",
       "2                                             code  Failed   \n",
       "3                                      description  Failed   \n",
       "4                                 ['Code', 'code']  Passed   \n",
       "5                   ['Description', 'description']  Passed   \n",
       "6                                                   Passed   \n",
       "7                          ['Code', 'Description']  Failed   \n",
       "8                          ['code', 'description']  Failed   \n",
       "9                             ['state', 'country']  Failed   \n",
       "10                            ['state', 'country']  Failed   \n",
       "11                            ['state', 'country']  Failed   \n",
       "12                            ['state', 'country']  Failed   \n",
       "13                              ['state', 'state']  Passed   \n",
       "14                            ['state', 'country']  Failed   \n",
       "15                            ['state', 'country']  Failed   \n",
       "16               ['Cancelled', 'CancellationCode']  Failed   \n",
       "17               ['Cancelled', 'CancellationCode']  Failed   \n",
       "18        ['CancellationCode', 'CancellationCode']  Passed   \n",
       "19  ['CRSElapsedTime', 'CRSArrTime', 'CRSDepTime']  Failed   \n",
       "20  ['CRSElapsedTime', 'CRSArrTime', 'CRSDepTime']  Failed   \n",
       "21            ['CRSElapsedTime', 'CRSElapsedTime']  Passed   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Bad Data  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Total missing values: 4; Rows #: 8, 36, 52, 79   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Total missing values: 3; Rows #: 8, 15, 16   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Total missing values: 4; Rows #: 8, 36, 52, 79   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Total missing values: 3; Rows #: 8, 15, 16   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Same values in Source and Target   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Same values in Source and Target   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Same Row counts in Source and Target   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Duplicates: 7; Duplicate Row Indices: 5, 7, 1495, 1502, 1503, 1504, 1505   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Duplicates: 7; Duplicate Row Indices: 5, 7, 1495, 1502, 1503, 1504, 1505   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Number of incorrect records: 12; Incorrect records 'iata': '', '01B', '01C', '01D', 'CLD', 'HHH', 'MIB', 'MQT', 'RCA', 'RDR', 'SCE', 'SKA'   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Number of incorrect records: 12; Incorrect records 'iata': '', '01B', '01C', '01D', 'CLD', 'HHH', 'MIB', 'MQT', 'RCA', 'RDR', 'SCE', 'SKA'   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Number of incorrect records: 9; Incorrect records 'iata': '01A', 'CLD', 'HHH', 'MIB', 'MQT', 'RCA', 'RDR', 'SCE', 'SKA'   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Number of incorrect records: 9; Incorrect records 'iata': '01A', 'CLD', 'HHH', 'MIB', 'MQT', 'RCA', 'RDR', 'SCE', 'SKA'   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Same values in Source and Target   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Incorrect state abbreviation: 35; Incorrect records: , DC, PR, PR, NA, PR, AS, CQ, CQ, GU, NA, PR, NA, NA, AS, PR, PR, NA, NA, NA, PR, PR, NA, VI, VI, CQ, CQ, PR, PR, VI, VI, PR, VI, AS, AS   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Incorrect state abbreviation: 35; Incorrect records: , DC, PR, PR, NA, PR, AS, CQ, CQ, GU, NA, PR, NA, NA, AS, PR, PR, NA, NA, NA, PR, PR, NA, VI, VI, CQ, CQ, PR, PR, VI, VI, PR, VI, AS, AS   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Number of incorrect records: 4; Rows with bad data: 42, 78, 203, 345   \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Number of incorrect records: 4; Rows with bad data: 42, 78, 203, 345   \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Same values in Source and Target   \n",
       "19  Number of incorrect records: 248; Rows #: 1, 2, 3, 4, 5, 6, 7, 8, 12, 16, 17, 18, 19, 21, 22, 29, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 55, 56, 58, 64, 71, 72, 73, 74, 76, 77, 78, 79, 82, 83, 84, 88, 91, 92, 97, 100, 102, 105, 107, 111, 112, 115, 122, 125, 126, 129, 133, 136, 139, 140, 141, 145, 146, 147, 148, 150, 152, 153, 154, 156, 159, 161, 165, 166, 168, 170, 172, 173, 175, 177, 178, 180, 181, 183, 186, 187, 191, 194, 196, 200, 201, 203, 206, 208, 211, 213, 222, 223, 225, 228, 233, 234, 236, 237, 238, 239, 240, 242, 243, 246, 247, 248, 252, 255, 260, 266, 268, 271, 272, 277, 284, 285, 286, 287, 290, 291, 293, 300, 301, 302, 303, 308, 310, 314, 316, 317, 318, 319, 326, 327, 329, 331, 333, 336, 337, 338, 340, 341, 352, 353, 355, 359, 360, 362, 363, 364, 368, 369, 384, 386, 391, 397, 398, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 427, 429, 436, 447, 448, 449, 451, 452, 453, 454, 455, 456, 459, 462, 471, 473, 475, 476, 477, 478, 479, 480, 481, 482, 486, 491, 492, 493, 494, 495, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 519, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532   \n",
       "20  Number of incorrect records: 248; Rows #: 1, 2, 3, 4, 5, 6, 7, 8, 12, 16, 17, 18, 19, 21, 22, 29, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 55, 56, 58, 64, 71, 72, 73, 74, 76, 77, 78, 79, 82, 83, 84, 88, 91, 92, 97, 100, 102, 105, 107, 111, 112, 115, 122, 125, 126, 129, 133, 136, 139, 140, 141, 145, 146, 147, 148, 150, 152, 153, 154, 156, 159, 161, 165, 166, 168, 170, 172, 173, 175, 177, 178, 180, 181, 183, 186, 187, 191, 194, 196, 200, 201, 203, 206, 208, 211, 213, 222, 223, 225, 228, 233, 234, 236, 237, 238, 239, 240, 242, 243, 246, 247, 248, 252, 255, 260, 266, 268, 271, 272, 277, 284, 285, 286, 287, 290, 291, 293, 300, 301, 302, 303, 308, 310, 314, 316, 317, 318, 319, 326, 327, 329, 331, 333, 336, 337, 338, 340, 341, 352, 353, 355, 359, 360, 362, 363, 364, 368, 369, 384, 386, 391, 397, 398, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 427, 429, 436, 447, 448, 449, 451, 452, 453, 454, 455, 456, 459, 462, 471, 473, 475, 476, 477, 478, 479, 480, 481, 482, 486, 491, 492, 493, 494, 495, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 519, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532   \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Same values in Source and Target   \n",
       "\n",
       "   Test Case  \n",
       "0      TC #1  \n",
       "1      TC #2  \n",
       "2      TC #3  \n",
       "3      TC #4  \n",
       "4      TC #5  \n",
       "5      TC #6  \n",
       "6      TC #7  \n",
       "7      TC #8  \n",
       "8      TC #9  \n",
       "9     TC #10  \n",
       "10    TC #11  \n",
       "11    TC #12  \n",
       "12    TC #13  \n",
       "13    TC #14  \n",
       "14    TC #15  \n",
       "15    TC #16  \n",
       "16    TC #17  \n",
       "17    TC #18  \n",
       "18    TC #19  \n",
       "19    TC #20  \n",
       "20    TC #21  \n",
       "21    TC #22  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print check results:\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content of DataFrame cells\n",
    "Raw_Data_Validation = pd.read_csv(csv_path, keep_default_na=False)\n",
    "Raw_Data_Validation.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8b4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Local PySpark (Python-3.7.9 / Spark-3.0.1 )",
   "language": "python",
   "name": "py3spark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
